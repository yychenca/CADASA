{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing, pipeline, metrics, model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json('../input/two-sigma-connect-rental-listing-inquiries/train.json.zip', convert_dates=['created'])\n",
    "test_data = pd.read_json('../input/two-sigma-connect-rental-listing-inquiries/test.json.zip', convert_dates=['created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create target variables\n",
    "\n",
    "We need to convert the raw target variable into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['target'] = train_data['interest_level'].apply(lambda x: 0 if x=='low' else 1 if x=='medium' else 2)\n",
    "train_data['low'] = train_data['interest_level'].apply(lambda x: 1 if x=='low' else 0)\n",
    "train_data['medium'] = train_data['interest_level'].apply(lambda x: 1 if x=='medium' else 0)\n",
    "train_data['high'] = train_data['interest_level'].apply(lambda x: 1 if x=='high' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge training and testing data\n",
    "So we don't have to perform transformations twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "full_data=pd.concat([train_data,test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['bathrooms','bedrooms','latitude','longitude','price']\n",
    "cat_vars = ['building_id','manager_id','display_address','street_address']\n",
    "text_vars = ['description','features']\n",
    "date_var = 'created'\n",
    "image_var = 'photos'\n",
    "id_var = 'listing_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date/time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['created_datetime'] = pd.to_datetime(full_data['created'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "full_data['created_year']=full_data['created_datetime'].apply(lambda x:x.year) ## low variant\n",
    "full_data['created_datetime'] = pd.to_datetime(full_data['created'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "full_data['created_month']=full_data['created_datetime'].apply(lambda x:x.month)\n",
    "full_data['created_day']=full_data['created_datetime'].apply(lambda x:x.day)\n",
    "full_data['created_dayofweek']=full_data['created_datetime'].apply(lambda x:x.dayofweek)\n",
    "full_data['created_dayofyear']=full_data['created_datetime'].apply(lambda x:x.dayofyear)\n",
    "full_data['created_weekofyear']=full_data['created_datetime'].apply(lambda x:x.weekofyear)\n",
    "full_data['created_hour']=full_data['created_datetime'].apply(lambda x:x.hour)\n",
    "full_data['created_epoch']=full_data['created_datetime'].apply(lambda x:x.value//10**9)\n",
    "\n",
    "date_num_vars = ['created_month','created_dayofweek','created_dayofyear'\n",
    "                 ,'created_weekofyear','created_hour','created_epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolocation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"geo_area_50\"] = \\\n",
    "    full_data[['latitude', 'longitude']]\\\n",
    "    .apply(lambda x:(int(x[0]*50)%50)*50+(int(-x[1]*50)%50),axis=1)                                         \n",
    "                         \n",
    "\n",
    "full_data[\"geo_area_100\"] = \\\n",
    "    full_data[['latitude', 'longitude']]\\\n",
    "    .apply(lambda x:(int(x[0]*100)%100)*100+(int(-x[1]*100)%100),axis=1)                                         \n",
    "  \n",
    "\n",
    "full_data[\"geo_area_200\"] = \\\n",
    "    full_data[['latitude', 'longitude']]\\\n",
    "    .apply(lambda x:(int(x[0]*200)%200)*200+(int(-x[1]*200)%200),axis=1)                                         \n",
    "\n",
    "import math\n",
    "\n",
    "# Financial district\n",
    "lat=40.705628\n",
    "lon=-74.010278\n",
    "full_data['distance_to_fi'] = full_data[['latitude', 'longitude']].apply(lambda x:math.sqrt((x[0]-lat)**2+(x[1]-lon)**2), axis=1)\n",
    "\n",
    "# Central park\n",
    "lat = 40.785091\n",
    "lon = -73.968285\n",
    "full_data['distance_to_cp'] = full_data[['latitude', 'longitude']].apply(lambda x:math.sqrt((x[0]-lat)**2+(x[1]-lon)**2), axis=1)\n",
    "\n",
    "\n",
    "geo_cat_vars = ['geo_area_50', 'geo_area_100', 'geo_area_200']\n",
    "\n",
    "geo_num_vars = ['distance_to_fi', 'distance_to_cp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features: basic engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['rooms'] = full_data['bedrooms'] + full_data['bathrooms'] \n",
    "full_data['num_of_photos'] = full_data['photos'].apply(lambda x:len(x))\n",
    "full_data['num_of_features'] = full_data['features'].apply(lambda x:len(x))\n",
    "full_data['len_of_desc'] = full_data['description'].apply(lambda x:len(x))\n",
    "full_data['words_of_desc'] = full_data['description'].apply(lambda x:len(re.sub('['+string.punctuation+']', '', x).split()))\n",
    "\n",
    "\n",
    "full_data['nums_of_desc'] = full_data['description']\\\n",
    "        .apply(lambda x:re.sub('['+string.punctuation+']', '', x).split())\\\n",
    "        .apply(lambda x: len([s for s in x if s.isdigit()]))\n",
    "        \n",
    "full_data['has_phone'] = full_data['description'].apply(lambda x:re.sub('['+string.punctuation+']', '', x).split())\\\n",
    "        .apply(lambda x: [s for s in x if s.isdigit()])\\\n",
    "        .apply(lambda x: len([s for s in x if len(str(s))==10]))\\\n",
    "        .apply(lambda x: 1 if x>0 else 0)\n",
    "full_data['has_email'] = full_data['description'].apply(lambda x: 1 if '@renthop.com' in x else 0)\n",
    "\n",
    "full_data['building_id_is_zero'] = full_data['building_id'].apply(lambda x:1 if x=='0' else 0)\n",
    "\n",
    "additional_num_vars = ['rooms','num_of_photos','num_of_features','len_of_desc',\n",
    "                    'words_of_desc','has_phone','has_email','building_id_is_zero']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric-Numeric interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['avg_word_len'] = full_data[['len_of_desc','words_of_desc']]\\\n",
    "                                    .apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "    \n",
    "full_data['price_per_room'] = full_data[['price','rooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_bedroom'] = full_data[['price','bedrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_bathroom'] = full_data[['price','bathrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_feature'] = full_data[['price','num_of_features']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_photo'] = full_data[['price','num_of_photos']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_word'] = full_data[['price','words_of_desc']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_by_desc_len'] = full_data[['price','len_of_desc']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "\n",
    "\n",
    "full_data['photos_per_room'] = full_data[['num_of_photos','rooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['photos_per_bedroom'] = full_data[['num_of_photos','bedrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['photos_per_bathroom'] = full_data[['num_of_photos','bathrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "\n",
    "full_data['desc_len_per_room'] = full_data[['len_of_desc','rooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['desc_len_per_bedroom'] = full_data[['len_of_desc','bedrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['desc_len_per_bathroom'] = full_data[['len_of_desc','bathrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['desc_len_per_word'] = full_data[['len_of_desc','words_of_desc']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['desc_len_per_numeric'] = full_data[['len_of_desc','nums_of_desc']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "\n",
    "full_data['features_per_room'] = full_data[['num_of_features','rooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['features_per_bedroom'] = full_data[['num_of_features','bedrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['features_per_bathroom'] = full_data[['num_of_features','bathrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['features_per_photo'] = full_data[['num_of_features','num_of_photos']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['features_per_word'] = full_data[['num_of_features','words_of_desc']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['features_by_desc_len'] = full_data[['num_of_features','len_of_desc']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "\n",
    "\n",
    "interactive_num_vars = ['avg_word_len','price_per_room','price_per_bedroom','price_per_bathroom',\n",
    "                        'price_per_feature','price_per_photo','price_per_word','price_by_desc_len',\n",
    "                        'photos_per_room','photos_per_bedroom','photos_per_bathroom',\n",
    "                        'desc_len_per_room','desc_len_per_bedroom','desc_len_per_bathroom','desc_len_per_word',\n",
    "                        'desc_len_per_numeric','features_per_room','features_per_bedroom','features_per_bathroom',\n",
    "                        'features_per_photo','features_per_word','features_by_desc_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 2.91 ms, total: 17.5 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "display=full_data[\"display_address\"].value_counts()\n",
    "manager_id=full_data[\"manager_id\"].value_counts()\n",
    "building_id=full_data[\"building_id\"].value_counts()\n",
    "street=full_data[\"street_address\"].value_counts()\n",
    "bedrooms=full_data[\"bedrooms\"].value_counts()\n",
    "bathrooms=full_data[\"bathrooms\"].value_counts()\n",
    "created_dayofyear=full_data[\"created_dayofyear\"].value_counts()\n",
    "created_weekofyear=full_data[\"created_weekofyear\"].value_counts()\n",
    "\n",
    "full_data[\"display_count\"]=full_data[\"display_address\"].apply(lambda x:display[x])\n",
    "full_data[\"manager_count\"]=full_data[\"manager_id\"].apply(lambda x:manager_id[x])  \n",
    "full_data[\"building_count\"]=full_data[\"building_id\"].apply(lambda x:building_id[x])\n",
    "full_data[\"street_count\"]=full_data[\"street_address\"].apply(lambda x:street[x])\n",
    "full_data[\"bedrooms_count\"]=full_data[\"bedrooms\"].apply(lambda x:bedrooms[x])\n",
    "full_data[\"bathrooms_count\"]=full_data[\"bathrooms\"].apply(lambda x:bathrooms[x])\n",
    "full_data[\"created_dayofyear_count\"]=full_data[\"created_dayofyear\"].\\\n",
    "    apply(lambda x:created_dayofyear[x])\n",
    "full_data[\"created_weekofyear_count\"]=full_data[\"created_weekofyear\"].\\\n",
    "    apply(lambda x:created_weekofyear[x])\n",
    "\n",
    "count_vars = ['manager_count', 'building_count', 'street_count', 'bedrooms_count',\n",
    "       'bathrooms_count', 'created_dayofyear_count', 'created_weekofyear_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric-categorical interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['price_percentile_by_manager', 'price_percentile_by_building']\n"
     ]
    }
   ],
   "source": [
    "num_cat_vars =[]\n",
    "price_by_manager = full_data.groupby('manager_id')['price'].agg([np.min,np.max,np.median,np.mean]).reset_index()\n",
    "price_by_manager.columns = ['manager_id','min_price_by_manager',\n",
    "                            'max_price_by_manager','median_price_by_manager','mean_price_by_manager']\n",
    "full_data = pd.merge(full_data,price_by_manager, how='left',on='manager_id')\n",
    "\n",
    "price_by_building = full_data.groupby('building_id')['price'].agg([np.min,np.max,np.median,np.mean]).reset_index()\n",
    "price_by_building.columns = ['building_id','min_price_by_building',\n",
    "                            'max_price_by_building','median_price_by_building','mean_price_by_building']\n",
    "full_data = pd.merge(full_data,price_by_building, how='left',on='building_id')\n",
    "\n",
    "\n",
    "full_data['price_percentile_by_manager']=\\\n",
    "            full_data[['price','min_price_by_manager','max_price_by_manager']]\\\n",
    "            .apply(lambda x:(x[0]-x[1])/(x[2]-x[1]) if (x[2]-x[1])!=0 else 0.5,\n",
    "                  axis=1)\n",
    "full_data['price_percentile_by_building']=\\\n",
    "            full_data[['price','min_price_by_building','max_price_by_building']]\\\n",
    "            .apply(lambda x:(x[0]-x[1])/(x[2]-x[1]) if (x[2]-x[1])!=0 else 0.5,\n",
    "                  axis=1)\n",
    "\n",
    "\n",
    "num_cat_vars.append('price_percentile_by_manager')\n",
    "num_cat_vars.append('price_percentile_by_building')\n",
    "\n",
    "print (num_cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-way categorical features interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['building_id',\n",
       " 'manager_id',\n",
       " 'display_address',\n",
       " 'street_address',\n",
       " 'building_id-manager_id',\n",
       " 'building_id-display_address',\n",
       " 'building_id-street_address',\n",
       " 'manager_id-display_address',\n",
       " 'manager_id-street_address',\n",
       " 'display_address-street_address']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for comb in itertools.combinations(cat_vars, 2):\n",
    "    comb_var_name = comb[0] +'-'+ comb[1]\n",
    "    full_data [comb_var_name] = full_data [ comb[0]].astype(str) +'_' + full_data [ comb[1]].astype(str)\n",
    "    cat_vars.append(comb_var_name)\n",
    "\n",
    "cat_vars    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text features\n",
    "\n",
    "* Here we are using CountVectorizer but you are encouraged to give TfidfVectorizer a try.\n",
    "\n",
    "* The parameter of max_features to be tuned\n",
    "\n",
    "* The outputs are sparse matrices which can be merged with numpy arrays using scipy.stats.sparse.hstack function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "cntvec = CountVectorizer(stop_words='english', max_features=200)\n",
    "feature_sparse =cntvec.fit_transform(full_data[\"features\"]\\\n",
    "                                     .apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x])))\n",
    "\n",
    "feature_vars = ['feature_' + v for v in cntvec.vocabulary_]\n",
    "\n",
    "cntvec = CountVectorizer(stop_words='english', max_features=100)\n",
    "desc_sparse = cntvec.fit_transform(full_data[\"description\"])\n",
    "desc_vars = ['desc_' + v for v in cntvec.vocabulary_]\n",
    "\n",
    "\n",
    "cntvec = CountVectorizer(stop_words='english', max_features=10)\n",
    "st_addr_sparse = cntvec.fit_transform(full_data[\"street_address\"])\n",
    "st_addr_vars = ['desc_' + v for v in cntvec.vocabulary_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features - label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding building_id\n",
      "Label Encoding manager_id\n",
      "Label Encoding display_address\n",
      "Label Encoding street_address\n",
      "Label Encoding building_id-manager_id\n",
      "Label Encoding building_id-display_address\n",
      "Label Encoding building_id-street_address\n",
      "Label Encoding manager_id-display_address\n",
      "Label Encoding manager_id-street_address\n",
      "Label Encoding display_address-street_address\n",
      "Label-encoded feaures: ['building_id_le', 'manager_id_le', 'display_address_le', 'street_address_le', 'building_id-manager_id_le', 'building_id-display_address_le', 'building_id-street_address_le', 'manager_id-display_address_le', 'manager_id-street_address_le', 'display_address-street_address_le']\n"
     ]
    }
   ],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "\n",
    "LE_vars=[]\n",
    "LE_map=dict()\n",
    "for cat_var in cat_vars:\n",
    "    print (\"Label Encoding %s\" % (cat_var))\n",
    "    LE_var=cat_var+'_le'\n",
    "    full_data[LE_var]=LBL.fit_transform(full_data[cat_var])\n",
    "    LE_vars.append(LE_var)\n",
    "    LE_map[cat_var]=LBL.classes_\n",
    "    \n",
    "print (\"Label-encoded feaures: %s\" % (LE_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features - one hot encoding\n",
    "\n",
    "The output is a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot-encoding finished in 0.843020 seconds\n",
      "OHE_sparse size : (124011, 340241)\n",
      "One-hot encoded catgorical feature samples : ['building_0', 'building_00005cb939f9986300d987652c933e15', 'building_00024d77a43f0606f926e2312513845c', 'building_000ae4b7db298401cdae2b0ba1ea8146', 'building_0012f1955391bca600ec301035b97b65', 'building_0021440c04241281a436ec21accc40b1', 'building_002d1eba40aa0a6610e04ff20543585f', 'building_003d8740e21484dcc2280639b25539a4', 'building_00480e54b53fe77d17964be3f8307a99', 'building_00553d95d22484bcc36831c9248d1dbc', 'building_0055c8662ba19e95f78df97592d2b83e', 'building_0056dbdf2881b76f2a0171eb753ec9e0', 'building_0059ae562b9e338a59eaf962cb3eedd2', 'building_005e0f8d7fb7b92be351cbf1dd985149', 'building_0067f166111490e7af7f1a878a67bb5e', 'building_0070bc94a3f80aa717bb15708e98ba54', 'building_0071cda335745940cdae1dc31abfc701', 'building_0078281cd69f4bfec17e42e5cf5eecd9', 'building_0078c2ab46afba9969637ac83621901e', 'building_007ae1cd90420f18bad7b6892a9a1411', 'building_007cd8edc45c6cfbcabd88f70d59a513', 'building_008d3e3a11295305966844713b685f7d', 'building_008ff72d77a8fc85eccfc4ec33ec09a3', 'building_0095cb49c423ec7b204e26d76c56bd35', 'building_009c6ad006e8fd679991c5f8cffaef9f', 'building_009f494b0636f32b96b41926ec7c4bf2', 'building_00a4e18de6c9a7bbec33c77e0588a3b9', 'building_00a61b88186b5115356374b0f5dd0d1e', 'building_00a7b4a6aec7ca1a1635c622918b68f0', 'building_00a94a38fcda000b4448370839a25ac8', 'building_00b2da856a75f0f5690996b0a0b1f397', 'building_00bafd8e05682a7c7e36b4046acd0f1b', 'building_00bb734cde488aa3e1f3e5f1376b9c13', 'building_00cca782a37fc2bb91b080ede56fa7cf', 'building_00ce59a4de554163bda36549de6bf967', 'building_00d1b109f921cd8bc69a203bf35a9bac', 'building_00dfd2bccb9127f2e7966ff29ae1e060', 'building_00e3e6bb0d19bb601842c0ab9589f9a2', 'building_00e8bbc4c74980a06c187165d9a5869e', 'building_00e980b7c97376eb19e0b1be650ccb64', 'building_00ecc203c49a4651cf186de65f308ac1', 'building_00fdda7f129d05ab200c31c0c6de8dfd', 'building_00ffdfd150acc0b097182bbf9dd1db28', 'building_0103d0d57f197a73cdfd0f2f26870d74', 'building_010435ab3b0b415421d583937a55283e', 'building_0106f282d2dfe616303b86e5b68df6b4', 'building_010f3d0141cd76667ca8e3d86e221cf2', 'building_0114c80bf2a9027612083e354d7fbdbc', 'building_0117976b081298aea99e21c327ab25a4', 'building_011a3c781df937c2991a3832b547b158', 'building_01298c8fd1e6e332fb4c188a7183a206', 'building_012fcf2833e0e07897b682ab6f82be3b', 'building_013a96b772f0e46731faee50ad25d727', 'building_01401bc9a8908b2d6ffa84ebf9e1b984', 'building_0145e758b990b8d2648ee57c30762d76', 'building_0152c6255a4e29051b817ce6f3f6dd6f', 'building_0155fa9629c4d68dbe9106b9ac3866ad', 'building_015901f6966b695aec0bda32e36423d6', 'building_015bf4a41140bb7304d338437192f2ab', 'building_015cf622b143eb8703307cf591e9dd46', 'building_01601e509316d5e48176d0f034e04f9f', 'building_016124e48651db465762bfbaf7a9080b', 'building_0162edae269da1472fcbdf4f61df7c7a', 'building_0165775b1775642fb0f71595e83484ba', 'building_0166aa8add8bdc29ca360ab1db5c77f9', 'building_016e30568187a4bd83bf86ca02837544', 'building_017c4715165fe36e5a4372ebf15207f1', 'building_017c9eb62166b050a144adad22b91c00', 'building_017e4ac152c10d537fb2acb3743f2162', 'building_018023115a3d3d3273b25a3357e5358a', 'building_0180389cfd65c7037149466dc934afd3', 'building_01813414c43aedaf8f1b1fb74cef3f99', 'building_018b0a85428622d9a6447fd475cf8bff', 'building_018cd3169a68bd83a92c341d8349b77d', 'building_01904e878eec9c80a40d70f6495454c2', 'building_0195041256b2514a6047a340b0561c3e', 'building_019adbb79eb99ed4c4b9dea91571aa91', 'building_019ce6c2904c70141b3c6fd6d7557344', 'building_019e909a65d7d2e3bf22c6334bf15a7e', 'building_01a430b383a468bcfb6a6dec9f6d42cd', 'building_01a8c78a8ec0234b5e9bd8645fb2ce43', 'building_01acba2c701ccf3528ddf17f1006f694', 'building_01ae28a1834d9bb940cfa2daa78b59c6', 'building_01bb059f7b7619ed7a5f74a97b9ce2ed', 'building_01bd855b1c9b786e37c13c25e5a81fda', 'building_01bfd6631a820706cb16bae93585d998', 'building_01cb79b2d06a9844231c42b3f05eb0c2', 'building_01cb7ce5bc25ca98fcca6ed5236c3224', 'building_01cd1cd0b21bbd22da7381a248d4fdc8', 'building_01cefee671bc17927058c0c579d459cb', 'building_01d767115586534b39d5224710dc56a4', 'building_01d79491cfd8271eaf73a5d69a759ef0', 'building_01d7a001b3a497c25c3a01955d45c339', 'building_01db3503f72909222100231ff6905a78', 'building_01df496b33f2402c5c18076b5f45c916', 'building_01e23bdc82cbdb20a15d290c02572a5d', 'building_01ee5fb703946538f9a34e22f48939e9', 'building_01f27b3de1bf1ee3218e88e64c3315a0', 'building_01f582fe206ca52144a3ac43c14653f7', 'building_01f85713461b5be6a172f4c3db190668']\n"
     ]
    }
   ],
   "source": [
    "OHE = preprocessing.OneHotEncoder(sparse=True)\n",
    "start=time.time()\n",
    "OHE.fit(full_data[LE_vars])\n",
    "OHE_sparse=OHE.transform(full_data[LE_vars])\n",
    "                                   \n",
    "print ('One-hot-encoding finished in %f seconds' % (time.time()-start))\n",
    "\n",
    "\n",
    "OHE_vars = [var[:-3] + '_' + str(level).replace(' ','_')\\\n",
    "                for var in cat_vars for level in LE_map[var] ]\n",
    "\n",
    "print (\"OHE_sparse size :\" ,OHE_sparse.shape)\n",
    "print (\"One-hot encoded catgorical feature samples : %s\" % (OHE_vars[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features - mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "\n",
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=5, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    "\n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "\n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    "\n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    "\n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    "\n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    "\n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    "\n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg({'mean': 'mean', 'beta': 'size'})\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    "\n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    "\n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_encoder = MeanEncoder(categorical_features=['manager_id','building_id'])\n",
    "mean_encoded_train = mean_encoder.fit_transform(train_data, train_data['target'])\n",
    "mean_encoded_test = mean_encoder.transform(test_data)\n",
    "\n",
    "mean_coded_vars = list(set(mean_encoded_train.columns) - set(train_data.columns))\n",
    "mean_coded_vars.append('listing_id')\n",
    "full_data = pd.merge(full_data, \n",
    "                     pd.concat([mean_encoded_train[mean_coded_vars], mean_encoded_test[mean_coded_vars]]),\n",
    "                     how='left',\n",
    "                     on='listing_id'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 380) testing data size:  (74659, 380)\n"
     ]
    }
   ],
   "source": [
    "full_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+ geo_cat_vars +geo_num_vars+ count_vars + LE_vars + mean_coded_vars\n",
    "train_x = sparse.hstack([full_data[full_vars], \n",
    "                         feature_sparse, \n",
    "                         desc_sparse, \n",
    "                         st_addr_sparse]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars], \n",
    "                        feature_sparse, \n",
    "                        desc_sparse, \n",
    "                        st_addr_sparse]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + desc_vars + st_addr_vars    \n",
    "print (\"training data size: \", train_x.shape,\"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms_count',\n",
       " 'bedrooms_count',\n",
       " 'building_count',\n",
       " 'created_dayofyear_count',\n",
       " 'created_weekofyear_count',\n",
       " 'geo_area_100',\n",
       " 'geo_area_200',\n",
       " 'geo_area_50',\n",
       " 'manager_count',\n",
       " 'street_count'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'created_month', 'created_dayofweek', 'created_dayofyear', 'created_weekofyear', 'created_hour', 'created_epoch', 'rooms', 'num_of_photos', 'num_of_features', 'len_of_desc', 'words_of_desc', 'has_phone', 'has_email', 'building_id_is_zero', 'avg_word_len', 'price_per_room', 'price_per_bedroom', 'price_per_bathroom', 'price_per_feature', 'price_per_photo', 'price_per_word', 'price_by_desc_len', 'photos_per_room', 'photos_per_bedroom', 'photos_per_bathroom', 'desc_len_per_room', 'desc_len_per_bedroom', 'desc_len_per_bathroom', 'desc_len_per_word', 'desc_len_per_numeric', 'features_per_room', 'features_per_bedroom', 'features_per_bathroom', 'features_per_photo', 'features_per_word', 'features_by_desc_len', 'geo_area_50', 'geo_area_100', 'geo_area_200', 'manager_count', 'building_count', 'street_count', 'bedrooms_count', 'bathrooms_count', 'created_dayofyear_count', 'created_weekofyear_count', 'building_id_le', 'manager_id_le', 'display_address_le', 'street_address_le', 'building_id-manager_id_le', 'building_id-display_address_le', 'building_id-street_address_le', 'manager_id-display_address_le', 'manager_id-street_address_le', 'display_address-street_address_le', 'building_id_pred_1', 'manager_id_pred_2', 'building_id_pred_0', 'building_id_pred_2', 'manager_id_pred_0', 'manager_id_pred_1', 'listing_id'])-set(['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'created_month', 'created_dayofweek', 'created_dayofyear', 'created_weekofyear', 'created_hour', 'created_epoch', 'rooms', 'num_of_photos', 'num_of_features', 'len_of_desc', 'words_of_desc', 'has_phone', 'has_email', 'building_id_is_zero', 'avg_word_len', 'price_per_room', 'price_per_bedroom', 'price_per_bathroom', 'price_per_feature', 'price_per_photo', 'price_per_word', 'price_by_desc_len', 'photos_per_room', 'photos_per_bedroom', 'photos_per_bathroom', 'desc_len_per_room', 'desc_len_per_bedroom', 'desc_len_per_bathroom', 'desc_len_per_word', 'desc_len_per_numeric', 'features_per_room', 'features_per_bedroom', 'features_per_bathroom', 'features_per_photo', 'features_per_word', 'features_by_desc_len', 'norm_listing_id', 'building_id_le', 'manager_id_le', 'display_address_le', 'street_address_le', 'building_id-manager_id_le', 'building_id-display_address_le', 'building_id-street_address_le', 'manager_id-display_address_le', 'manager_id-street_address_le', 'display_address-street_address_le', 'building_id_pred_1', 'manager_id_pred_2', 'building_id_pred_0', 'building_id_pred_2', 'manager_id_pred_0', 'manager_id_pred_1', 'listing_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM \n",
    "\n",
    "Typically, GBDT model converges faster with a larger learning rate (e.g 0.1) than smaller learning rate however the accuracy may not be as promising. We will be using 0.1 as the learning rate for the rest of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.545721 + 0.00447754\n",
      "[100]\tcv_agg's multi_logloss: 0.533822 + 0.0050867\n",
      "[150]\tcv_agg's multi_logloss: 0.532546 + 0.00540632\n",
      "[200]\tcv_agg's multi_logloss: 0.533726 + 0.00491786\n",
      "Best iteration: 158, best score: 0.532456\n",
      "CPU times: user 5min 54s, sys: 2.4 s, total: 5min 57s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.1\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))\n",
    "# 0.549718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.573366 + 0.00341929\n",
      "[100]\tcv_agg's multi_logloss: 0.544896 + 0.00457299\n",
      "[150]\tcv_agg's multi_logloss: 0.536127 + 0.00458239\n",
      "[200]\tcv_agg's multi_logloss: 0.532382 + 0.00440243\n",
      "[250]\tcv_agg's multi_logloss: 0.530803 + 0.00433631\n",
      "[300]\tcv_agg's multi_logloss: 0.530336 + 0.00414269\n",
      "[350]\tcv_agg's multi_logloss: 0.530255 + 0.00417446\n",
      "Best iteration: 320, best score: 0.530150\n",
      "CPU times: user 10min 42s, sys: 4.01 s, total: 10min 46s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## listing ID\n",
    "Theoretically ID variable is not supposed to be included in training a model. However, for some reason listing_id appears to be correlated to the created date time and therefore might be a good candidate as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x7fa669675c18>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot('listing_id', 'created_epoch', full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_listing_id = full_data['listing_id'].min()\n",
    "max_listing_id = full_data['listing_id'].max()\n",
    "full_data['norm_listing_id']=full_data['listing_id'].apply(lambda x:np.float64((x-min_listing_id+1))/(max_listing_id-min_listing_id+1))\n",
    "listing_vars = [ 'norm_listing_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 381) testing data size:  (74659, 381)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+ geo_cat_vars +geo_num_vars + count_vars \\\n",
    "     + listing_vars\n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars], \n",
    "                         feature_sparse, \n",
    "                         desc_sparse, \n",
    "                         st_addr_sparse]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars], \n",
    "                        feature_sparse, \n",
    "                        desc_sparse, \n",
    "                        st_addr_sparse]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + desc_vars + st_addr_vars    \n",
    "print (\"training data size: \", train_x.shape,\"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.545356 + 0.00461699\n",
      "[100]\tcv_agg's multi_logloss: 0.533574 + 0.00493584\n",
      "[150]\tcv_agg's multi_logloss: 0.532052 + 0.0048654\n",
      "Best iteration: 136, best score: 0.531804\n",
      "CPU times: user 5min 28s, sys: 1.98 s, total: 5min 30s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.1\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.573278 + 0.00354571\n",
      "[100]\tcv_agg's multi_logloss: 0.544414 + 0.00501547\n",
      "[150]\tcv_agg's multi_logloss: 0.535681 + 0.00530418\n",
      "[200]\tcv_agg's multi_logloss: 0.532186 + 0.00529804\n",
      "[250]\tcv_agg's multi_logloss: 0.53069 + 0.00523651\n",
      "[300]\tcv_agg's multi_logloss: 0.530067 + 0.00522046\n",
      "[350]\tcv_agg's multi_logloss: 0.529986 + 0.00512631\n",
      "Best iteration: 344, best score: 0.529960\n",
      "CPU times: user 11min 33s, sys: 4.17 s, total: 11min 38s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_price = full_data.groupby(['building_id', 'display_address', 'bedrooms', 'bathrooms']).price.mean().reset_index()\n",
    "mkt_price = pd.merge(full_data[['building_id', 'display_address', 'bedrooms', 'bathrooms']],\n",
    "                     mkt_price, how='left', on=['building_id', 'display_address', 'bedrooms', 'bathrooms']).price\n",
    "full_data['mkt_price'] = mkt_price.values\n",
    "full_data['diff_to_mkt_price'] = full_data['price'] - full_data['mkt_price']\n",
    "full_data['ratio_to_mkt_price'] = full_data['price'] / full_data['mkt_price']\n",
    "\n",
    "price_vars = ['diff_to_mkt_price', 'ratio_to_mkt_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack \"HopScore\"\n",
    "\n",
    "Though it may not be 100% correlated it turns out that Renthop uses a system called [\"**HopScore**\"](https://www.renthop.com/agent-guide/the-hopscore) to rank listings. According to the official instruction there are three things to consider to improve HopScore:\n",
    "\n",
    "* Listing freshness\n",
    "* Listing quality\n",
    "* Manager performance\n",
    "\n",
    "This finding is a breakthrough when I worked on feature engineering for this competition and resulted quite a few fruitful ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing freshness and listing quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "# unique identifer for listings - photo links uniquely identify a listing\n",
    "full_data['photos_str'] = full_data['photos'].astype(str)\n",
    "full_data['listing_uid'] = full_data[['manager_id', 'building_id','photos_str']].apply(lambda x: hashlib.md5((x[0] + x[1] + x[2]).encode()).hexdigest(), axis=1 )\n",
    "full_data['posted_times'] = full_data.groupby('listing_uid').created_datetime.rank(method='first', na_option='top',pct=True)\n",
    "\n",
    "# Using html tag may improve listing quality\n",
    "full_data['num_of_html_tag']=full_data.description.apply(lambda x:x.count('<'))\n",
    "\n",
    "# Studies have shown that titles with excessive all caps and special characters give renters the impression \n",
    "# that the listing is fraudulent  i.e. BEAUTIFUL***APARTMENT***CHELSEA.\n",
    "full_data['num_of_#']=full_data.description.apply(lambda x:x.count('#'))\n",
    "full_data['num_of_!']=full_data.description.apply(lambda x:x.count('!'))\n",
    "full_data['num_of_$']=full_data.description.apply(lambda x:x.count('$'))\n",
    "full_data['num_of_*']=full_data.description.apply(lambda x:x.count('*'))\n",
    "full_data['num_of_>']=full_data.description.apply(lambda x:x.count('>'))\n",
    "full_data['num_of_puncs']=full_data['num_of_#'] + full_data['num_of_!'] + full_data['num_of_$'] + full_data['num_of_*'] + full_data['num_of_>']\n",
    "full_data['puncs_ratio'] = full_data['num_of_puncs']/full_data['len_of_desc']\n",
    "full_data['upper_char_ratio'] = full_data['description'].apply(lambda x: 0 if sum([s.isalpha() for s in x])==0 else sum([s.isalpha()&s.isupper() for s in x])/ sum([s.isalpha() for s in x]))\n",
    "\n",
    "# Accuracy of location/ address\n",
    "full_data['disp_is_street'] = (full_data['display_address'] == full_data['street_address'])*1\n",
    "full_data['disp_st_addr_word_ratio'] = full_data.apply(lambda x:len(x['display_address'].split(' '))/len(x['street_address'].split(' ')), axis=1)\n",
    "\n",
    "listing_quality_vars = ['disp_is_street', 'num_of_html_tag','num_of_#','num_of_!','num_of_$', 'num_of_*',\n",
    "                        'posted_times', 'disp_st_addr_word_ratio','upper_char_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 390) testing data size:  (74659, 390)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+ geo_cat_vars +geo_num_vars + count_vars \\\n",
    "    + listing_vars + listing_quality_vars\n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars], \n",
    "                         feature_sparse, \n",
    "                         desc_sparse, \n",
    "                         st_addr_sparse]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars], \n",
    "                        feature_sparse, \n",
    "                        desc_sparse, \n",
    "                        st_addr_sparse]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + desc_vars + st_addr_vars    \n",
    "print (\"training data size: \", train_x.shape,\"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.573034 + 0.00368081\n",
      "[100]\tcv_agg's multi_logloss: 0.544559 + 0.00456516\n",
      "[150]\tcv_agg's multi_logloss: 0.53591 + 0.00466528\n",
      "[200]\tcv_agg's multi_logloss: 0.532557 + 0.00456405\n",
      "[250]\tcv_agg's multi_logloss: 0.531003 + 0.00458374\n",
      "[300]\tcv_agg's multi_logloss: 0.530577 + 0.00471197\n",
      "Best iteration: 289, best score: 0.530488\n",
      "CPU times: user 10min 31s, sys: 3.72 s, total: 10min 34s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))\n",
    "\n",
    "# 0.547453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manager performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def p25(x):\n",
    "    return np.percentile(x, 25)\n",
    "def p50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def p75(x):\n",
    "    return np.percentile(x, 75)\n",
    "def nunique(x):\n",
    "    return np.size(np.unique(x))\n",
    "def max_min(x):\n",
    "    return np.max(x)-np.min(x)\n",
    "def p75_p25(x):\n",
    "    return np.percentile(x, 75)-np.percentile(x, 25)\n",
    "\n",
    "\n",
    "\n",
    "def get_group_stats(df, stat_funcs, target_column, group_column, ranking=False, ranking_pct=True):\n",
    "    aggr = df.groupby(group_column)[target_column].agg([v for v in stat_funcs.values()]).reset_index()\n",
    "    aggr.columns = [group_column] + [  target_column + '_' + k + '_by_' + group_column for k in stat_funcs.keys()]\n",
    "    aggr = df[[group_column]].merge(aggr, how='left', on=group_column)\n",
    "    \n",
    "    #rank\n",
    "    if ranking:\n",
    "        aggr[target_column + '_rank_by_' + group_column] = df.groupby(group_column)[target_column].rank(method='dense', \n",
    "                                                                                                    na_option='top',\n",
    "                                                                                                    pct=ranking_pct)\n",
    "    return aggr.drop(group_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_funcs = {\n",
    "#     'count_unique': nunique,\n",
    "    'mean': np.mean,\n",
    "    'min': np.min,\n",
    "    'max': np.max,\n",
    "    'std': np.std,\n",
    "    'p25': p25,\n",
    "    'p50': p50,\n",
    "    'p75': p75,\n",
    "    'skew': skew,\n",
    "    'kurtosis': kurtosis,\n",
    "    'max_min': max_min,\n",
    "    'p75_p25': p75_p25\n",
    "}\n",
    "\n",
    "\n",
    "mgr_aggr = pd.DataFrame()\n",
    "for num_var in num_vars + additional_num_vars + listing_quality_vars:\n",
    "    mgr_aggr = pd.concat([mgr_aggr,\n",
    "                          get_group_stats(full_data, stat_funcs,\n",
    "                                          target_column=num_var, group_column='manager_id', ranking=False)\n",
    "                          ],\n",
    "                         axis=1\n",
    "                         )\n",
    "    \n",
    "## manager activeness\n",
    "mgr_aggr = pd.concat([mgr_aggr,\n",
    "                      get_group_stats(full_data, {'max_min': max_min, 'p75_p25': p75_p25},\n",
    "                                      target_column='created_epoch', group_column='manager_id', ranking=False)\n",
    "                      ],\n",
    "                     axis=1\n",
    "                     )\n",
    "\n",
    "mgr_aggr = pd.concat([mgr_aggr,\n",
    "                      get_group_stats(full_data, {'nunique': nunique},\n",
    "                                      target_column='created_dayofyear', group_column='manager_id', ranking=False)\n",
    "                      ],\n",
    "                     axis=1\n",
    "                     )\n",
    "\n",
    "## Buildings managed by the manager\n",
    "mgr_aggr = pd.concat([mgr_aggr,\n",
    "                      get_group_stats(full_data, {'nunique': nunique},\n",
    "                                      target_column='building_id', group_column='manager_id', ranking=False)\n",
    "                      ],\n",
    "                     axis=1\n",
    "                     )\n",
    "\n",
    "## Areas \n",
    "for aggr_col in ['geo_area_50', 'geo_area_100', 'geo_area_200']:\n",
    "    mgr_aggr = pd.concat([mgr_aggr,\n",
    "                          get_group_stats(full_data, {'nunique': nunique},\n",
    "                                          target_column=aggr_col, group_column='manager_id', ranking=False)\n",
    "                          ],\n",
    "                         axis=1\n",
    "                         )\n",
    "\n",
    "## Price fairness    \n",
    "for aggr_col in ['diff_to_mkt_price', 'ratio_to_mkt_price']:\n",
    "    mgr_aggr = pd.concat([mgr_aggr,\n",
    "                          get_group_stats(full_data, {'mean': np.mean},\n",
    "                                          target_column=aggr_col, group_column='manager_id', ranking=False)\n",
    "                          ],\n",
    "                         axis=1\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 639) testing data size:  (74659, 639)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+ geo_cat_vars + count_vars \\\n",
    "    + listing_vars + listing_quality_vars\n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars],\n",
    "                         feature_sparse,\n",
    "                         desc_sparse,\n",
    "                         st_addr_sparse,\n",
    "                         mgr_aggr]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars],\n",
    "                        feature_sparse,\n",
    "                        desc_sparse,\n",
    "                        st_addr_sparse,\n",
    "                        mgr_aggr]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + desc_vars + st_addr_vars\n",
    "print(\"training data size: \", train_x.shape,\n",
    "      \"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.572387 + 0.00324105\n",
      "[100]\tcv_agg's multi_logloss: 0.543591 + 0.00447352\n",
      "[150]\tcv_agg's multi_logloss: 0.53509 + 0.00463003\n",
      "[200]\tcv_agg's multi_logloss: 0.531591 + 0.00472818\n",
      "[250]\tcv_agg's multi_logloss: 0.529993 + 0.00471097\n",
      "[300]\tcv_agg's multi_logloss: 0.529779 + 0.00478228\n",
      "Best iteration: 288, best score: 0.529715\n",
      "CPU times: user 24min 36s, sys: 5.57 s, total: 24min 41s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))\n",
    "# Best iteration: 306, best score: 0.531753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar for building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_funcs = {\n",
    "#     'count_unique': nunique,\n",
    "    'mean': np.mean,\n",
    "    'min': np.min,\n",
    "    'max': np.max,\n",
    "    'std': np.std,\n",
    "    'p25': p25,\n",
    "    'p50': p50,\n",
    "    'p75': p75,\n",
    "    'skew': skew,\n",
    "    'kurtosis': kurtosis,\n",
    "    'max_min': max_min,\n",
    "    'p75_p25': p75_p25\n",
    "}\n",
    "\n",
    "\n",
    "building_aggr = pd.DataFrame()\n",
    "\n",
    "building_aggr = pd.concat([building_aggr,\n",
    "                      get_group_stats(full_data, stat_funcs,\n",
    "                                      target_column='price', group_column='building_id', ranking=False)\n",
    "                      ],\n",
    "                     axis=1\n",
    "                     )\n",
    "    \n",
    "\n",
    "## Buildings managed by the manager\n",
    "building_aggr = pd.concat([building_aggr,\n",
    "                      get_group_stats(full_data, {'nunique': nunique},\n",
    "                                      target_column='manager_id', group_column='building_id', ranking=False)\n",
    "                      ],\n",
    "                     axis=1\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 653) testing data size:  (74659, 653)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+ geo_cat_vars +geo_num_vars + count_vars \\\n",
    "    + listing_vars + listing_quality_vars\n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars],\n",
    "                         feature_sparse,\n",
    "                         desc_sparse,\n",
    "                         st_addr_sparse,\n",
    "                         mgr_aggr,\n",
    "                         building_aggr]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars],\n",
    "                        feature_sparse,\n",
    "                        desc_sparse,\n",
    "                        st_addr_sparse,\n",
    "                        mgr_aggr,\n",
    "                       building_aggr]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + desc_vars + st_addr_vars\n",
    "print(\"training data size: \", train_x.shape,\n",
    "      \"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.571973 + 0.00341128\n",
      "[100]\tcv_agg's multi_logloss: 0.54311 + 0.00421872\n",
      "[150]\tcv_agg's multi_logloss: 0.534122 + 0.0047964\n",
      "[200]\tcv_agg's multi_logloss: 0.530522 + 0.00488872\n",
      "[250]\tcv_agg's multi_logloss: 0.529113 + 0.00483096\n",
      "[300]\tcv_agg's multi_logloss: 0.52891 + 0.0051341\n",
      "Best iteration: 291, best score: 0.528779\n",
      "CPU times: user 27min 2s, sys: 5.76 s, total: 27min 8s\n",
      "Wall time: 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))\n",
    "# Best iteration: 306, best score: 0.531753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Location Location!!!\n",
    "\n",
    "Not all listings were created equally. Location is one of the most dominant factors when seeking a place to live. When we think of location we are not only talking about the absolute location but the relative location, e.g. proximity to facilities such as school, transportations and supermarkets. Unfortunately, these information are not provided by the dataset naively but thanks to Kaggler [Farron](https://www.kaggle.com/mmueller) who graciously shared his secret sauce which brilliantly hacked the proximity information and helped him win the second place in this competition. Here's what he did: \n",
    "> It consists of kmeans cluster of (latitude, longitude) followed by computing statistics like the ones above and cluster center distances. In order to get some proxies for PoI's in the neighborhood, I created clusters after filtering the dataset based on certain words in the descriptions. That way, I estimated coordinates for things like \"supermarket\", \"shopping\", \"subway\", \"bus\", \"health\", \"fitness\", \"park\" etc. Afterwards I created minimal distances to those locations as well as counts based on different distances cut-offs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parks\n",
    "\n",
    "The biggest challenge for replicating Faron's great idea is to figure out the appropriate number of clusters for each category. How can we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import vincenty\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "park_listings = full_data[full_data[['description', 'features']].apply(lambda x: 'park' in x[0] or 'park' in x[1], axis=1)][['latitude', 'longitude']]\n",
    "\n",
    "park_n_clusters = 25\n",
    "kms = KMeans(n_clusters=park_n_clusters)\n",
    "kms.fit(park_listings)\n",
    "\n",
    "park_dist_data = pd.DataFrame(kms.transform(full_data[['latitude', 'longitude']]),\n",
    "                              columns = ['dist_to_park_' + str(i) for i in range(park_n_clusters)]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 678) testing data size:  (74659, 678)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars +geo_num_vars+ geo_cat_vars + count_vars \\\n",
    "    + listing_vars + listing_quality_vars  \n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars],\n",
    "                         feature_sparse,\n",
    "                         desc_sparse,\n",
    "                         st_addr_sparse,\n",
    "                         mgr_aggr,\n",
    "                        building_aggr,\n",
    "                        park_dist_data]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars],\n",
    "                        feature_sparse,\n",
    "                        desc_sparse,\n",
    "                        st_addr_sparse,\n",
    "                        mgr_aggr,\n",
    "                       building_aggr,\n",
    "                       park_dist_data]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + desc_vars + st_addr_vars\n",
    "print(\"training data size: \", train_x.shape,\n",
    "      \"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.569651 + 0.0032432\n",
      "[100]\tcv_agg's multi_logloss: 0.539857 + 0.00456987\n",
      "[150]\tcv_agg's multi_logloss: 0.531129 + 0.00481811\n",
      "[200]\tcv_agg's multi_logloss: 0.527458 + 0.00483663\n",
      "[250]\tcv_agg's multi_logloss: 0.526404 + 0.00466007\n",
      "[300]\tcv_agg's multi_logloss: 0.525873 + 0.00471233\n",
      "Best iteration: 299, best score: 0.525851\n",
      "CPU times: user 30min 16s, sys: 6.14 s, total: 30min 22s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your reference, we can use the following snippet to fine tune the optimal number clusters\n",
    "\n",
    "```python\n",
    "\n",
    "scores = []\n",
    "for park_n_clusters in (10, 15, 20, 25, 30):\n",
    "    kms = KMeans(n_clusters=park_n_clusters)\n",
    "    kms.fit(park_listings)\n",
    "\n",
    "    park_dist_data = pd.DataFrame(kms.transform(full_data[['latitude', 'longitude']]),\n",
    "                                  columns=['dist_to_park_' +\n",
    "                                      str(i) for i in range(park_n_clusters)]\n",
    "                                 )\n",
    "\n",
    "    full_num_vars = num_vars + date_num_vars + additional_num_vars + \\\n",
    "        interactive_num_vars + listing_vars + listing_quality_vars + magic_vars + \\\n",
    "        num_cat_vars + mean_coded_vars + distance_vars\n",
    "    full_cat_vars = LE_vars\n",
    "    full_vars = full_num_vars + full_cat_vars\n",
    "    train_x = sparse.hstack([full_data[full_vars],\n",
    "                             feature_sparse,\n",
    "                             desc_sparse,\n",
    "                             st_addr_sparse,\n",
    "                             mgr_aggr,\n",
    "                            park_dist_data]).tocsr()[:train_size]\n",
    "    train_y = full_data['target'][:train_size].values\n",
    "    test_x = sparse.hstack([full_data[full_vars],\n",
    "                            feature_sparse,\n",
    "                            desc_sparse,\n",
    "                            st_addr_sparse,\n",
    "                            mgr_aggr,\n",
    "                            park_dist_data]).tocsr()[train_size:]\n",
    "    test_y = full_data['target'][train_size:].values\n",
    "\n",
    "    full_vars = full_vars + feature_vars + desc_vars + st_addr_vars\n",
    "    print(\"training data size: \", train_x.shape,\n",
    "          \"testing data size: \", test_x.shape)\n",
    "\n",
    "    lgb_params = dict()\n",
    "    lgb_params['objective'] = 'multiclass'\n",
    "    lgb_params['num_class'] = 3\n",
    "    lgb_params['learning_rate'] = 0.05\n",
    "    lgb_params['num_leaves'] = 63\n",
    "    lgb_params['max_depth'] = 15\n",
    "    lgb_params['min_gain_to_split '] = 1\n",
    "    lgb_params['subsample'] = 0.7\n",
    "    lgb_params['colsample_bytree'] = 0.7\n",
    "    lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "    lgb_params['seed'] = 42\n",
    "\n",
    "    lgb_cv = lgb.cv(lgb_params,\n",
    "                    lgb.Dataset(train_x,\n",
    "                                label=train_y\n",
    "                                ),\n",
    "                    num_boost_round=100000,\n",
    "                    nfold=5,\n",
    "                    stratified=True,\n",
    "                    shuffle=True,\n",
    "                    early_stopping_rounds=50,\n",
    "                    seed=42,\n",
    "                    verbose_eval=100)\n",
    "\n",
    "    best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "    best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "    print('Best iteration: %d, best score: %f' % (best_iteration, best_score))\n",
    "    scores.append([park_n_clusters, best_score])\n",
    "scores = np.array(scores)\n",
    "best_park_n_clusters = scores[:, 0][(np.argmin(scores[:, 1]))]\n",
    "print('best number of clusters: %d, best score: %f' % (best_park_n_clusters, np.min(scores[:, 1])))\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_listings = full_data[full_data[['description', 'features']].apply(lambda x: 'subway' in x[0] or 'subway' in x[1], axis=1)][['latitude', 'longitude']]\n",
    "\n",
    "subway_n_clusters = 400\n",
    "kms = KMeans(n_clusters=subway_n_clusters)\n",
    "kms.fit(subway_listings)\n",
    "\n",
    "subway_dist_data = pd.DataFrame(kms.transform(full_data[['latitude', 'longitude']]),\n",
    "                              columns = ['dist_to_subway_' + str(i) for i in range(subway_n_clusters)]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 1078) testing data size:  (74659, 1078)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+geo_num_vars+ geo_cat_vars + count_vars \\\n",
    "    + listing_vars + listing_quality_vars \n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars],\n",
    "                         feature_sparse,\n",
    "                         desc_sparse,\n",
    "                         st_addr_sparse,\n",
    "                         mgr_aggr,\n",
    "                        building_aggr,\n",
    "                        park_dist_data,\n",
    "                        subway_dist_data]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars],\n",
    "                        feature_sparse,\n",
    "                        desc_sparse,\n",
    "                        st_addr_sparse,\n",
    "                        mgr_aggr,\n",
    "                       building_aggr,\n",
    "                       park_dist_data,\n",
    "                       subway_dist_data]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + desc_vars + st_addr_vars\n",
    "print(\"training data size: \", train_x.shape,\n",
    "      \"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.569265 + 0.00342119\n",
      "[100]\tcv_agg's multi_logloss: 0.539553 + 0.00422727\n",
      "[150]\tcv_agg's multi_logloss: 0.530582 + 0.00450288\n",
      "[200]\tcv_agg's multi_logloss: 0.527164 + 0.00480983\n",
      "[250]\tcv_agg's multi_logloss: 0.526031 + 0.00481716\n",
      "[300]\tcv_agg's multi_logloss: 0.525936 + 0.00473577\n",
      "Best iteration: 288, best score: 0.525873\n",
      "CPU times: user 57min 23s, sys: 7.78 s, total: 57min 31s\n",
      "Wall time: 14min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item2vec\n",
    "\n",
    "We can use the same idea for word2vec to embed any items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy ## Spacy is the de-facto NLP tool used by industry\n",
    "from gensim.models import FastText  \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "## Tokenize a sentence\n",
    "def seq_to_token(seq, nlp=nlp):\n",
    "    doc = nlp(str(seq).lower())\n",
    "    tokens = [token.text for token in doc if not ( token.is_space | token.is_stop|token.like_num)]\n",
    "    return tokens\n",
    "\n",
    "## Convert tokens to vector\n",
    "def tokens_to_vec(tokens, model, vec_size=10):\n",
    "    if len(tokens)==0:\n",
    "        return np.zeors(vec_size)\n",
    "    else:\n",
    "        return np.array([emb_model[token] for token in tokens]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed building id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manager_id\n",
       "0000abd7518b94c35a90d64b56fbf3e6    [d64120032c7c77ed2d3caf743b33201b, b491b11c7ea...\n",
       "001ce808ce1720e24a9510e014c69707    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "003fc4e9a70053082f131b1054966aaf                                         [0, 0, 0, 0]\n",
       "00607a02f6efd9c6c7c588826e471ee9    [bbd82dada059fe400bd515589333bae9, 8e9dc82b439...\n",
       "00995ff28d79127ed2dca8320e9e7d09    [77fccbedf29d0035ea311701fd715823, ad67f6181a4...\n",
       "Name: building_id, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 1: Generate \"sentences\"\n",
    "building_by_mgr = full_data.groupby('manager_id')['building_id'].apply(list)\n",
    "building_by_mgr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.7843275 , -1.0873846 ,  1.5095539 , -0.11258737,  0.16320401,\n",
       "        0.32354936,  2.1196125 ,  1.2524652 ,  0.8789119 , -0.78124624],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 2: Train a fasttext model\n",
    "building_model = FastText(size=10, window=3, min_count=1, workers=16)  # instantiate\n",
    "building_model.build_vocab(sentences=building_by_mgr)\n",
    "building_model.train(sentences=building_by_mgr.values, total_examples=len(building_by_mgr.values), epochs=5)\n",
    "\n",
    "## Take a look at the embedding for building_id 8a8b08e08888819a3e745005a8cd0408\n",
    "building_model['8a8b08e08888819a3e745005a8cd0408']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.86782306,  -1.1663593 ,   1.5430108 , ...,   1.3460227 ,\n",
       "          0.8868551 ,  -0.77050924],\n",
       "       [  0.5621958 ,  -1.432132  ,   1.7951    , ...,   1.7809668 ,\n",
       "          1.3062751 ,  -1.0434483 ],\n",
       "       [  0.5775995 ,  -1.5462695 ,   2.0648592 , ...,   1.9381046 ,\n",
       "          1.4727904 ,  -1.2262148 ],\n",
       "       ...,\n",
       "       [ 18.210459  , -16.519539  ,   4.8748493 , ...,  17.479746  ,\n",
       "         -1.0313543 ,   3.023367  ],\n",
       "       [  1.0618416 ,  -1.1884751 ,   1.8580693 , ...,   1.3193855 ,\n",
       "          0.9811291 ,  -0.9330204 ],\n",
       "       [  1.3361573 ,  -1.7097892 ,   1.9929698 , ...,   1.9206597 ,\n",
       "          1.1060035 ,  -0.9139155 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 3: Embed building ids\n",
    "building_emb = full_data['building_id'].apply(lambda x:building_model[x]).values\n",
    "building_emb = np.array([e.reshape(1,-1) for e in building_emb]).reshape(-1,10)\n",
    "building_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed manager id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.5459034 , -2.4338746 , -1.7066944 , ...,  1.869851  ,\n",
       "        -4.170246  , -0.44711676],\n",
       "       [-1.4953406 , -2.119001  , -0.2823045 , ...,  0.35475844,\n",
       "         0.11215224,  0.21007243],\n",
       "       [-3.6713762 , -2.7806685 , -0.3667828 , ...,  1.0348134 ,\n",
       "         1.0134226 ,  0.61292624],\n",
       "       ...,\n",
       "       [-1.6645426 , -2.3138847 , -1.2993264 , ...,  0.1948381 ,\n",
       "        -0.13117908,  0.1935277 ],\n",
       "       [-2.1199002 , -4.4403143 , -0.19360483, ...,  0.4009747 ,\n",
       "         0.60684615, -0.8989814 ],\n",
       "       [-1.173622  , -0.34279838,  0.13306461, ...,  0.21445557,\n",
       "         0.22133149,  1.1361825 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager_by_building = full_data.groupby('building_id')['manager_id'].apply(list)  \n",
    "manager_model = FastText(size=10, window=3, min_count=1, workers=16)\n",
    "manager_model.build_vocab(sentences=manager_by_building)\n",
    "manager_model.train(sentences=manager_by_building.values, \n",
    "                    total_examples=len(manager_by_building.values), epochs=5)\n",
    "manager_emb = full_data['manager_id'].apply(lambda x:manager_model[x]).values\n",
    "manager_emb = np.array([e.reshape(1,-1) for e in manager_emb]).reshape(-1,10)\n",
    "manager_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02809998, -2.0764682 , -1.8587314 , ...,  0.74020034,\n",
       "        -4.07501   , -1.1552163 ],\n",
       "       [-1.5539856 , -2.0964093 , -0.3568625 , ...,  0.29643664,\n",
       "         0.25107074,  0.03389387],\n",
       "       [-3.6056962 , -2.7186322 , -0.22760876, ...,  0.7978077 ,\n",
       "         1.1487135 ,  0.24353907],\n",
       "       ...,\n",
       "       [-1.9285547 , -2.365765  , -1.4261793 , ...,  0.18406631,\n",
       "        -0.11812768,  0.24255364],\n",
       "       [-2.193354  , -4.4679985 , -0.34445256, ...,  0.35324544,\n",
       "         0.82622594, -0.9537938 ],\n",
       "       [-0.9998246 , -0.48436055,  0.30979523, ...,  0.22766794,\n",
       "         0.41234887,  0.91283065]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager_by_building = full_data.groupby('building_id')['manager_id'].apply(list)  \n",
    "manager_model = FastText(size=10, window=3, min_count=1, workers=16)\n",
    "manager_model.build_vocab(sentences=manager_by_building)\n",
    "manager_model.train(sentences=manager_by_building.values, \n",
    "                    total_examples=len(manager_by_building.values), epochs=5)\n",
    "manager_emb = full_data['manager_id'].apply(lambda x:manager_model[x]).values\n",
    "manager_emb = np.array([e.reshape(1,-1) for e in manager_emb]).reshape(-1,10)\n",
    "manager_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 1098) testing data size:  (74659, 1098)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+geo_num_vars+ geo_cat_vars + count_vars \\\n",
    "    + listing_vars + listing_quality_vars  \n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars],\n",
    "                         feature_sparse,\n",
    "                         desc_sparse,\n",
    "                         st_addr_sparse,\n",
    "                         mgr_aggr,\n",
    "                        building_aggr,\n",
    "                        park_dist_data,\n",
    "                        subway_dist_data,\n",
    "                        manager_emb,\n",
    "                        building_emb]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars],\n",
    "                        feature_sparse,\n",
    "                        desc_sparse,\n",
    "                        st_addr_sparse,\n",
    "                        mgr_aggr,\n",
    "                       building_aggr,\n",
    "                       park_dist_data,\n",
    "                       subway_dist_data,\n",
    "                       manager_emb,\n",
    "                    building_emb]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "\n",
    "print(\"training data size: \", train_x.shape,\n",
    "      \"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.568772 + 0.00378623\n",
      "[100]\tcv_agg's multi_logloss: 0.538713 + 0.00493945\n",
      "[150]\tcv_agg's multi_logloss: 0.53024 + 0.0056358\n",
      "[200]\tcv_agg's multi_logloss: 0.526608 + 0.00564483\n",
      "[250]\tcv_agg's multi_logloss: 0.525218 + 0.00563892\n",
      "[300]\tcv_agg's multi_logloss: 0.525288 + 0.00579725\n",
      "Best iteration: 260, best score: 0.525112\n",
      "CPU times: user 35min 37s, sys: 4.93 s, total: 35min 42s\n",
      "Wall time: 17min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The magic feature\n",
    "\n",
    "Firstly mentioned by Grand Master Silogram\n",
    "https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31765\n",
    "\n",
    "Discovered and made available to public by another Grand Master KazAnova\n",
    "https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870\n",
    "\n",
    "It may contain the information when the listing was actually created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_date = pd.read_csv(\"../input/twosigma-magic-feature/listing_image_time.csv\")\n",
    "\n",
    "image_date.columns = [\"listing_id\", \"image_time_stamp\"]\n",
    "full_data = pd.merge(full_data, image_date, on=\"listing_id\", how=\"left\")\n",
    "magic_vars = ['image_time_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 1101) testing data size:  (74659, 1101)\n"
     ]
    }
   ],
   "source": [
    "full_num_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars+geo_num_vars+ geo_cat_vars + count_vars \\\n",
    "    + listing_vars + listing_quality_vars + magic_vars + price_vars\n",
    "full_cat_vars = LE_vars + mean_coded_vars\n",
    "full_vars = full_num_vars + full_cat_vars\n",
    "train_x = sparse.hstack([full_data[full_vars],\n",
    "                         feature_sparse,\n",
    "                         desc_sparse,\n",
    "                         st_addr_sparse,\n",
    "                         mgr_aggr,\n",
    "                        building_aggr,\n",
    "                        park_dist_data,\n",
    "                        subway_dist_data,\n",
    "                        manager_emb,\n",
    "                        building_emb]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "test_x = sparse.hstack([full_data[full_vars],\n",
    "                        feature_sparse,\n",
    "                        desc_sparse,\n",
    "                        st_addr_sparse,\n",
    "                        mgr_aggr,\n",
    "                       building_aggr,\n",
    "                       park_dist_data,\n",
    "                       subway_dist_data,\n",
    "                       manager_emb,\n",
    "                    building_emb]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "\n",
    "print(\"training data size: \", train_x.shape,\n",
    "      \"testing data size: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's multi_logloss: 0.558739 + 0.00365682\n",
      "[100]\tcv_agg's multi_logloss: 0.526644 + 0.00504349\n",
      "[150]\tcv_agg's multi_logloss: 0.517466 + 0.00515362\n",
      "[200]\tcv_agg's multi_logloss: 0.513826 + 0.00522849\n",
      "[250]\tcv_agg's multi_logloss: 0.512581 + 0.00527144\n",
      "[300]\tcv_agg's multi_logloss: 0.512623 + 0.00508304\n",
      "Best iteration: 272, best score: 0.512414\n",
      "CPU times: user 37min 31s, sys: 5.08 s, total: 37min 36s\n",
      "Wall time: 18min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'multiclass'\n",
    "lgb_params['num_class'] = 3\n",
    "lgb_params['learning_rate'] = 0.05\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 1\n",
    "lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "lgb_params['seed']=42\n",
    "\n",
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=100000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=50)\n",
    "\n",
    "\n",
    "best_score = min(lgb_cv['multi_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['multi_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text embedding (optional)\n",
    "\n",
    "The pretrained FastText embedding can be downloaded and installed using the following commands:\n",
    "\n",
    "```shell\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
    "!python -m spacy init-model en ../embedding/crawl-300d-2M --vectors-loc ../embedding/crawl-300d-2M.vec.zip\n",
    "```\n",
    "\n",
    "Then in Python:\n",
    "\n",
    "```Python\n",
    "import spacy  \n",
    "nlp_fasttext = spacy.load(\"../embedding/crawl-300d-2M\")\n",
    "# nlp_glove = spacy.load(\"en_core_web_lg\")\n",
    "def seq_to_vec(seq, nlp, dim=300):\n",
    "    doc = nlp(str(seq))\n",
    "    vec = np.array(\n",
    "        [\n",
    "            token.vector\n",
    "            for token in doc\n",
    "            if not ( token.is_space | token.is_oov)\n",
    "        ]\n",
    "    ).mean(axis=0)\n",
    "    if isinstance(vec, np.ndarray):\n",
    "        return vec\n",
    "    else:\n",
    "        return np.zeros((dim))\n",
    "desc_emb = np.array([v for v in full_data[\"description\"].fillna('').apply(lambda x:seq_to_vec(x, nlp_fasttext)).values])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
